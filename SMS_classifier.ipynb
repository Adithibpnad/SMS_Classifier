{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx1X9dg0afo4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "p5ALJRBTa5x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is named 'spam.csv' and is located in the current working directory\n",
        "file_path = 'spam.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "spam = pd.read_csv(file_path, encoding='latin-1', usecols=[0, 1], skiprows=1, names=[\"label\", \"message\"])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "spam.head()\n"
      ],
      "metadata": {
        "id": "9ECmYLdnbjv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam.describe()"
      ],
      "metadata": {
        "id": "IfgZ4yChbpis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam.info()"
      ],
      "metadata": {
        "id": "jMz_n1ohbx1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam.isnull().sum()"
      ],
      "metadata": {
        "id": "RodIDzjXb3Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam['label'] = spam['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
        "spam['label']=spam['label'].astype(int)"
      ],
      "metadata": {
        "id": "3vM-vX4Pb7wc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam.duplicated().sum(),spam.shape"
      ],
      "metadata": {
        "id": "j0RA0cX_cGNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam=spam.drop_duplicates(keep='first')\n",
        "spam.shape"
      ],
      "metadata": {
        "id": "3qdTav1AcMCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam['label']"
      ],
      "metadata": {
        "id": "Z0D6e-z0cSOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(spam['label'].value_counts(),labels=['Not Spam','Spam'], autopct='%1.1f%%')\n",
        "plt.title('Distribution of Spam vs. Not Spam')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ApRoLQ-icV-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam['num_char']=spam['message'].apply(len)\n",
        "spam.head()"
      ],
      "metadata": {
        "id": "HEPbVtzccdH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam['num_words']=spam['message'].apply(lambda x : len(word_tokenize(x)))\n",
        "spam.head()"
      ],
      "metadata": {
        "id": "eI9PR1Mecmfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(spam[spam['label'] == 0]['num_char'], color='blue')\n",
        "sns.histplot(spam[spam['label'] == 1]['num_char'], color='red')"
      ],
      "metadata": {
        "id": "7n765xVPc4Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(spam[spam['label'] == 0]['num_words'], color='blue')\n",
        "sns.histplot(spam[spam['label'] == 1]['num_words'], color='red')"
      ],
      "metadata": {
        "id": "MVe-LwjjdA-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(spam,hue='label')"
      ],
      "metadata": {
        "id": "fuQhF6M_dRnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "punctuation= string.punctuation\n",
        "nltk.download('punkt')\n",
        "#!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "# going -> go  ,sleeps ->sleep\n",
        "\n",
        "\n",
        "\n",
        "def text_transform(x):\n",
        "  x=x.lower()\n",
        "  x = nltk.word_tokenize(x)\n",
        "  x=[word for word in x if (word not in stop_words) and (word.isalnum()) and (word not in punctuation)]\n",
        "  x = [stemmer.stem(word) for word in x]\n",
        "\n",
        "  return \" \".join(x)\n",
        "\n",
        "\n",
        "text_transform(\"HI HOW ARE YOU ? !,  he goes to sleep   \")\n"
      ],
      "metadata": {
        "id": "lnTcLoFGddIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(text_transform(spam['message'][0]))"
      ],
      "metadata": {
        "id": "Iiy6E6S2dkAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(spam['message'][0])"
      ],
      "metadata": {
        "id": "o6OASobsdoyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam['text_transformed']=spam['message'].apply(text_transform)\n",
        "spam.head()"
      ],
      "metadata": {
        "id": "CW90ONcxdr9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spam\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\n",
        "\n",
        "    (spam[spam['label']==1]['text_transformed']).str.cat(sep=\" \")\n",
        ")\n",
        "\n",
        "# Display the word cloud using Matplotlib\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VJw9VbWudx3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spam\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\n",
        "\n",
        "    (spam[spam['label']==0]['text_transformed']).str.cat(sep=\" \")\n",
        ")\n",
        "\n",
        "# Display the word cloud using Matplotlib\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a2AItMw2d5Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer()\n",
        "X=cv.fit_transform(spam['text_transformed']).toarray()\n",
        "X.shape, spam['text_transformed'].shape"
      ],
      "metadata": {
        "id": "CF3j89ebd-4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=spam['label'].values"
      ],
      "metadata": {
        "id": "LJVKy6LHeGN5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WlLqcmTLeSnx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train,y_train)\n",
        "nb_pred = nb_classifier.predict(X_test)\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "nb_report = classification_report(y_test, nb_pred)\n",
        "nb_accuracy"
      ],
      "metadata": {
        "id": "-D3LPgCZegC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg = LogisticRegression(C=20.0,max_iter=1000)\n",
        "lg.fit(X_train,y_train)\n",
        "lg_pred = lg.predict(X_test)\n",
        "lg_accuracy = accuracy_score(y_test, lg_pred)\n",
        "lg_report = classification_report(y_test, lg_pred)\n",
        "lg_accuracy"
      ],
      "metadata": {
        "id": "Vn26XyDIeiFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv = SVC(C=10.0)\n",
        "sv.fit(X_train,y_train)\n",
        "sv_pred = sv.predict(X_test)\n",
        "sv_accuracy = accuracy_score(y_test, sv_pred)\n",
        "sv_report = classification_report(y_test, sv_pred)\n",
        "sv_accuracy"
      ],
      "metadata": {
        "id": "v_-gndSRem5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naive Bayes Classifier:\")\n",
        "print(f\"Accuracy: {nb_accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", nb_report)\n",
        "\n",
        "print(\"\\nLogistic Regression Classifier:\")\n",
        "print(f\"Accuracy: {lg_accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", lg_report)\n",
        "\n",
        "print(\"\\nSupport Vector Machine Classifier:\")\n",
        "print(f\"Accuracy: {sv_accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", sv_report)"
      ],
      "metadata": {
        "id": "wWq1t9ZGeo4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}